{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "신경망 예제.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BqYIreqNHV8",
        "outputId": "fac5e7ed-b772-433e-d64b-dcc8e744024b"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu111\n",
            "11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05YRsM-7SiYL",
        "outputId": "3641acb4-6eec-4e29-d924-dbc6542f9a28"
      },
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.8)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.1)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.0.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Cn_mtATV8o"
      },
      "source": [
        "import os.path as osp\n",
        "from math import ceil\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, DenseGraphConv, dense_mincut_pool\n",
        "from torch_geometric.utils import to_dense_batch, to_dense_adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p43mslwrkACr"
      },
      "source": [
        "\n",
        "path = \"/content\"\n",
        "dataset = TUDataset(path, name='PROTEINS').shuffle()\n",
        "n = len(dataset)\n",
        "average_nodes = int(dataset.data.x.size(0) / len(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hPPqEUgkb2y"
      },
      "source": [
        "\n",
        "n = len(dataset) // 10 \n",
        "test_dataset = dataset[:n]\n",
        "val_dataset = dataset[n:2 * n]\n",
        "train_dataset = dataset[2 * n:]\n",
        "test_loader = DataLoader(test_dataset, batch_size=128)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hid93QQ9ZpPb",
        "outputId": "e7a42fac-b6cd-4c28-894d-13adcd8ad7d5"
      },
      "source": [
        "sample = dataset[:70]\n",
        "print(sample)\n",
        "print(sample[56])\n",
        "print(sample[56].x)\n",
        "print(sample[56].edge_index)\n",
        "print(sample[56].y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROTEINS(70)\n",
            "Data(edge_index=[2, 116], x=[30, 3], y=[1])\n",
            "tensor([[1., 0., 0.],\n",
            "        [1., 0., 0.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.]])\n",
            "tensor([[ 0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,\n",
            "          3,  3,  4,  4,  4,  4,  4,  5,  5,  5,  6,  6,  6,  7,  7,  7,  8,  8,\n",
            "          8,  8,  9,  9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 12, 12, 12, 13,\n",
            "         13, 13, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 16, 16, 17, 17, 17, 18,\n",
            "         18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22,\n",
            "         22, 22, 23, 23, 23, 24, 24, 24, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27,\n",
            "         28, 28, 28, 29, 29, 29, 29, 29],\n",
            "        [12, 13, 14, 15,  5, 19, 20, 21, 22,  7, 22, 26, 27, 28, 29,  4,  6,  8,\n",
            "         14, 15,  3,  5,  7,  8, 15,  1,  4, 22,  3,  8, 22,  2,  4, 29,  3,  4,\n",
            "          6, 29, 10, 11, 12,  9, 11, 12,  9, 10, 12,  0,  9, 10, 11, 13, 14,  0,\n",
            "         12, 14,  0,  3, 12, 13, 15,  0,  3,  4, 14, 29, 17, 24, 16, 18, 23, 17,\n",
            "         19, 20, 21,  1, 18, 20, 21,  1, 18, 19, 21,  1, 18, 19, 20,  1,  2,  5,\n",
            "          6, 29, 17, 24, 25, 16, 23, 25, 23, 24, 26,  2, 25, 27, 28,  2, 26, 28,\n",
            "          2, 26, 27,  2,  7,  8, 15, 22]])\n",
            "tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZiFqRMghBnI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joEzoPvik10X",
        "outputId": "64a3b7e9-db67-41df-fec6-a57a19c6124f"
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, hidden_channels=32):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        num_nodes = ceil(0.5 * average_nodes)\n",
        "        self.pool1 = Linear(hidden_channels, num_nodes)\n",
        "\n",
        "        self.conv2 = DenseGraphConv(hidden_channels, hidden_channels)\n",
        "        num_nodes = ceil(0.5 * num_nodes)\n",
        "        self.pool2 = Linear(hidden_channels, num_nodes)\n",
        "\n",
        "        self.conv3 = DenseGraphConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        x, mask = to_dense_batch(x, batch)\n",
        "        adj = to_dense_adj(edge_index, batch)\n",
        "\n",
        "        s = self.pool1(x)\n",
        "        x, adj, mc1, o1 = dense_mincut_pool(x, adj, s, mask)\n",
        "\n",
        "        x = F.relu(self.conv2(x, adj))\n",
        "        s = self.pool2(x)\n",
        "\n",
        "        x, adj, mc2, o2 = dense_mincut_pool(x, adj, s)\n",
        "\n",
        "        x = self.conv3(x, adj)\n",
        "\n",
        "        x = x.mean(dim=1)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1), mc1 + mc2, o1 + o2\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net(dataset.num_features, dataset.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out, mc_loss, o_loss = model(data.x, data.edge_index, data.batch)\n",
        "        loss = F.nll_loss(out, data.y.view(-1)) + mc_loss + o_loss\n",
        "        loss.backward()\n",
        "        loss_all += data.y.size(0) * loss.item()\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_dataset)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    loss_all = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        pred, mc_loss, o_loss = model(data.x, data.edge_index, data.batch)\n",
        "        loss = F.nll_loss(pred, data.y.view(-1)) + mc_loss + o_loss\n",
        "        loss_all += data.y.size(0) * loss.item()\n",
        "        correct += pred.max(dim=1)[1].eq(data.y.view(-1)).sum().item()\n",
        "\n",
        "    return loss_all / len(loader.dataset), correct / len(loader.dataset)\n",
        "\n",
        "\n",
        "best_val_acc = test_acc = 0\n",
        "best_val_loss = float('inf')\n",
        "start_patience = 50\n",
        "patience = 50\n",
        "for epoch in range(1, 3000):\n",
        "    train_loss = train(epoch)\n",
        "    _, train_acc = test(train_loader)\n",
        "    val_loss, val_acc = test(val_loader)\n",
        "    if val_loss < best_val_loss:\n",
        "        test_loss, test_acc = test(test_loader)\n",
        "        best_val_loss = val_loss\n",
        "        patience = start_patience\n",
        "    else:\n",
        "        patience -= 1\n",
        "        if patience == 0:\n",
        "            break\n",
        "    print('Epoch: {:03d}, '\n",
        "          'Train Loss: {:.3f}, Train Acc: {:.3f}, '\n",
        "          'Val Loss: {:.3f}, Val Acc: {:.3f}, '\n",
        "          'Test Loss: {:.3f}, Test Acc: {:.3f}'.format(epoch, train_loss,\n",
        "                                                       train_acc, val_loss,\n",
        "                                                       val_acc, test_loss,\n",
        "                                                       test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train Loss: 1.112, Train Acc: 0.605, Val Loss: 1.095, Val Acc: 0.577, Test Loss: 1.100, Test Acc: 0.541\n",
            "Epoch: 002, Train Loss: 1.083, Train Acc: 0.605, Val Loss: 1.075, Val Acc: 0.577, Test Loss: 1.085, Test Acc: 0.541\n",
            "Epoch: 003, Train Loss: 1.063, Train Acc: 0.605, Val Loss: 1.058, Val Acc: 0.577, Test Loss: 1.074, Test Acc: 0.541\n",
            "Epoch: 004, Train Loss: 1.047, Train Acc: 0.605, Val Loss: 1.045, Val Acc: 0.577, Test Loss: 1.067, Test Acc: 0.541\n",
            "Epoch: 005, Train Loss: 1.036, Train Acc: 0.605, Val Loss: 1.037, Val Acc: 0.577, Test Loss: 1.061, Test Acc: 0.541\n",
            "Epoch: 006, Train Loss: 1.029, Train Acc: 0.605, Val Loss: 1.031, Val Acc: 0.577, Test Loss: 1.053, Test Acc: 0.541\n",
            "Epoch: 007, Train Loss: 1.023, Train Acc: 0.605, Val Loss: 1.023, Val Acc: 0.577, Test Loss: 1.040, Test Acc: 0.541\n",
            "Epoch: 008, Train Loss: 1.015, Train Acc: 0.631, Val Loss: 1.015, Val Acc: 0.604, Test Loss: 1.027, Test Acc: 0.568\n",
            "Epoch: 009, Train Loss: 1.008, Train Acc: 0.690, Val Loss: 1.007, Val Acc: 0.649, Test Loss: 1.013, Test Acc: 0.613\n",
            "Epoch: 010, Train Loss: 1.000, Train Acc: 0.722, Val Loss: 1.000, Val Acc: 0.730, Test Loss: 1.000, Test Acc: 0.694\n",
            "Epoch: 011, Train Loss: 0.992, Train Acc: 0.734, Val Loss: 0.993, Val Acc: 0.712, Test Loss: 0.986, Test Acc: 0.766\n",
            "Epoch: 012, Train Loss: 0.985, Train Acc: 0.744, Val Loss: 0.987, Val Acc: 0.739, Test Loss: 0.974, Test Acc: 0.775\n",
            "Epoch: 013, Train Loss: 0.977, Train Acc: 0.744, Val Loss: 0.981, Val Acc: 0.730, Test Loss: 0.963, Test Acc: 0.775\n",
            "Epoch: 014, Train Loss: 0.970, Train Acc: 0.742, Val Loss: 0.976, Val Acc: 0.739, Test Loss: 0.954, Test Acc: 0.766\n",
            "Epoch: 015, Train Loss: 0.964, Train Acc: 0.745, Val Loss: 0.970, Val Acc: 0.748, Test Loss: 0.948, Test Acc: 0.784\n",
            "Epoch: 016, Train Loss: 0.957, Train Acc: 0.745, Val Loss: 0.964, Val Acc: 0.757, Test Loss: 0.944, Test Acc: 0.775\n",
            "Epoch: 017, Train Loss: 0.951, Train Acc: 0.754, Val Loss: 0.959, Val Acc: 0.775, Test Loss: 0.942, Test Acc: 0.775\n",
            "Epoch: 018, Train Loss: 0.946, Train Acc: 0.754, Val Loss: 0.954, Val Acc: 0.775, Test Loss: 0.940, Test Acc: 0.739\n",
            "Epoch: 019, Train Loss: 0.940, Train Acc: 0.755, Val Loss: 0.950, Val Acc: 0.766, Test Loss: 0.940, Test Acc: 0.730\n",
            "Epoch: 020, Train Loss: 0.936, Train Acc: 0.755, Val Loss: 0.947, Val Acc: 0.775, Test Loss: 0.940, Test Acc: 0.730\n",
            "Epoch: 021, Train Loss: 0.932, Train Acc: 0.758, Val Loss: 0.945, Val Acc: 0.784, Test Loss: 0.940, Test Acc: 0.739\n",
            "Epoch: 022, Train Loss: 0.928, Train Acc: 0.762, Val Loss: 0.944, Val Acc: 0.784, Test Loss: 0.940, Test Acc: 0.739\n",
            "Epoch: 023, Train Loss: 0.925, Train Acc: 0.763, Val Loss: 0.943, Val Acc: 0.784, Test Loss: 0.940, Test Acc: 0.748\n",
            "Epoch: 024, Train Loss: 0.923, Train Acc: 0.764, Val Loss: 0.942, Val Acc: 0.775, Test Loss: 0.942, Test Acc: 0.766\n",
            "Epoch: 025, Train Loss: 0.920, Train Acc: 0.765, Val Loss: 0.942, Val Acc: 0.775, Test Loss: 0.943, Test Acc: 0.757\n",
            "Epoch: 026, Train Loss: 0.919, Train Acc: 0.767, Val Loss: 0.941, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.757\n",
            "Epoch: 027, Train Loss: 0.917, Train Acc: 0.769, Val Loss: 0.940, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.757\n",
            "Epoch: 028, Train Loss: 0.916, Train Acc: 0.769, Val Loss: 0.940, Val Acc: 0.775, Test Loss: 0.943, Test Acc: 0.766\n",
            "Epoch: 029, Train Loss: 0.915, Train Acc: 0.769, Val Loss: 0.939, Val Acc: 0.766, Test Loss: 0.943, Test Acc: 0.766\n",
            "Epoch: 030, Train Loss: 0.914, Train Acc: 0.770, Val Loss: 0.937, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.757\n",
            "Epoch: 031, Train Loss: 0.913, Train Acc: 0.770, Val Loss: 0.937, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 032, Train Loss: 0.913, Train Acc: 0.770, Val Loss: 0.936, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 033, Train Loss: 0.912, Train Acc: 0.770, Val Loss: 0.935, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.739\n",
            "Epoch: 034, Train Loss: 0.911, Train Acc: 0.769, Val Loss: 0.934, Val Acc: 0.766, Test Loss: 0.945, Test Acc: 0.739\n",
            "Epoch: 035, Train Loss: 0.910, Train Acc: 0.769, Val Loss: 0.933, Val Acc: 0.766, Test Loss: 0.945, Test Acc: 0.739\n",
            "Epoch: 036, Train Loss: 0.910, Train Acc: 0.768, Val Loss: 0.933, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 037, Train Loss: 0.909, Train Acc: 0.769, Val Loss: 0.932, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 038, Train Loss: 0.908, Train Acc: 0.769, Val Loss: 0.932, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 039, Train Loss: 0.907, Train Acc: 0.768, Val Loss: 0.932, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 040, Train Loss: 0.907, Train Acc: 0.768, Val Loss: 0.932, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 041, Train Loss: 0.906, Train Acc: 0.768, Val Loss: 0.932, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 042, Train Loss: 0.905, Train Acc: 0.769, Val Loss: 0.932, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 043, Train Loss: 0.905, Train Acc: 0.769, Val Loss: 0.932, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 044, Train Loss: 0.904, Train Acc: 0.769, Val Loss: 0.933, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 045, Train Loss: 0.904, Train Acc: 0.771, Val Loss: 0.933, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 046, Train Loss: 0.903, Train Acc: 0.771, Val Loss: 0.933, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 047, Train Loss: 0.903, Train Acc: 0.771, Val Loss: 0.933, Val Acc: 0.766, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 048, Train Loss: 0.902, Train Acc: 0.772, Val Loss: 0.933, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 049, Train Loss: 0.902, Train Acc: 0.773, Val Loss: 0.934, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 050, Train Loss: 0.901, Train Acc: 0.773, Val Loss: 0.934, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 051, Train Loss: 0.901, Train Acc: 0.776, Val Loss: 0.935, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 052, Train Loss: 0.900, Train Acc: 0.774, Val Loss: 0.936, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 053, Train Loss: 0.900, Train Acc: 0.773, Val Loss: 0.937, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 054, Train Loss: 0.900, Train Acc: 0.773, Val Loss: 0.937, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 055, Train Loss: 0.899, Train Acc: 0.772, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 056, Train Loss: 0.899, Train Acc: 0.772, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 057, Train Loss: 0.899, Train Acc: 0.773, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 058, Train Loss: 0.898, Train Acc: 0.774, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 059, Train Loss: 0.898, Train Acc: 0.774, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 060, Train Loss: 0.898, Train Acc: 0.774, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 061, Train Loss: 0.897, Train Acc: 0.774, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 062, Train Loss: 0.897, Train Acc: 0.774, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 063, Train Loss: 0.897, Train Acc: 0.774, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 064, Train Loss: 0.897, Train Acc: 0.774, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 065, Train Loss: 0.896, Train Acc: 0.776, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 066, Train Loss: 0.896, Train Acc: 0.776, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 067, Train Loss: 0.896, Train Acc: 0.776, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 068, Train Loss: 0.895, Train Acc: 0.776, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 069, Train Loss: 0.895, Train Acc: 0.776, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 070, Train Loss: 0.895, Train Acc: 0.776, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 071, Train Loss: 0.895, Train Acc: 0.776, Val Loss: 0.939, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 072, Train Loss: 0.895, Train Acc: 0.776, Val Loss: 0.938, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 073, Train Loss: 0.894, Train Acc: 0.776, Val Loss: 0.939, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 074, Train Loss: 0.894, Train Acc: 0.777, Val Loss: 0.939, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 075, Train Loss: 0.894, Train Acc: 0.777, Val Loss: 0.939, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 076, Train Loss: 0.894, Train Acc: 0.776, Val Loss: 0.939, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 077, Train Loss: 0.894, Train Acc: 0.774, Val Loss: 0.939, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 078, Train Loss: 0.893, Train Acc: 0.773, Val Loss: 0.939, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 079, Train Loss: 0.893, Train Acc: 0.773, Val Loss: 0.939, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 080, Train Loss: 0.893, Train Acc: 0.772, Val Loss: 0.940, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 081, Train Loss: 0.893, Train Acc: 0.772, Val Loss: 0.940, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 082, Train Loss: 0.893, Train Acc: 0.772, Val Loss: 0.939, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 083, Train Loss: 0.892, Train Acc: 0.773, Val Loss: 0.939, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 084, Train Loss: 0.892, Train Acc: 0.773, Val Loss: 0.940, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 085, Train Loss: 0.892, Train Acc: 0.774, Val Loss: 0.940, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 086, Train Loss: 0.892, Train Acc: 0.774, Val Loss: 0.940, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 087, Train Loss: 0.892, Train Acc: 0.774, Val Loss: 0.940, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 088, Train Loss: 0.891, Train Acc: 0.774, Val Loss: 0.940, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 089, Train Loss: 0.891, Train Acc: 0.774, Val Loss: 0.940, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n",
            "Epoch: 090, Train Loss: 0.891, Train Acc: 0.773, Val Loss: 0.940, Val Acc: 0.775, Test Loss: 0.944, Test Acc: 0.748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoxjA9JAlzLq"
      },
      "source": [
        "      "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}